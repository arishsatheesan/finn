

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Internals &mdash; FINN  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Brevitas Export" href="brevitas_export.html" />
    <link rel="prev" title="End-to-End Flow" href="end_to_end_flow.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> FINN
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="end_to_end_flow.html">End-to-End Flow</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Internals</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#intermediate-representation-finn-onnx">Intermediate Representation: FINN-ONNX</a></li>
<li class="toctree-l2"><a class="reference internal" href="#custom-quantization-annotations">Custom Quantization Annotations</a></li>
<li class="toctree-l2"><a class="reference internal" href="#custom-operations-nodes">Custom Operations/Nodes</a></li>
<li class="toctree-l2"><a class="reference internal" href="#custom-onnx-execution-flow">Custom ONNX Execution Flow</a></li>
<li class="toctree-l2"><a class="reference internal" href="#modelwrapper">ModelWrapper</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#create-a-modelwrapper-instance">Create a ModelWrapper instance</a></li>
<li class="toctree-l3"><a class="reference internal" href="#access-the-onnx-graphproto-through-modelwrapper">Access the ONNX GraphProto through ModelWrapper</a></li>
<li class="toctree-l3"><a class="reference internal" href="#helper-functions-for-tensors">Helper functions for tensors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#analysis-pass">Analysis Pass</a></li>
<li class="toctree-l2"><a class="reference internal" href="#transformation-pass">Transformation Pass</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="brevitas_export.html">Brevitas Export</a></li>
<li class="toctree-l1"><a class="reference internal" href="nw_prep.html">Network Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="vivado_synth.html">Vivado HLS and Vivado Synthesis</a></li>
<li class="toctree-l1"><a class="reference internal" href="pynq_deploy.html">PYNQ Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="verification.html">Functional Verification</a></li>
<li class="toctree-l1"><a class="reference internal" href="source_code/finn.html">Source Code</a></li>
<li class="toctree-l1"><a class="reference internal" href="genindex.html">Index</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">FINN</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Internals</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/internals.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="internals">
<h1>Internals<a class="headerlink" href="#internals" title="Permalink to this headline">¶</a></h1>
<div class="section" id="intermediate-representation-finn-onnx">
<h2>Intermediate Representation: FINN-ONNX<a class="headerlink" href="#intermediate-representation-finn-onnx" title="Permalink to this headline">¶</a></h2>
<p>FINN uses <a class="reference external" href="https://github.com/onnx/onnx">ONNX</a> as an intermediate representation (IR) for neural networks. As such, almost every component inside FINN uses ONNX and its <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/PythonAPIOverview.md">Python API</a>, so you may want to familiarize yourself with how ONNX represents DNNs. Specifically, the <a class="reference external" href="https://github.com/onnx/onnx/blob/master/onnx/onnx.proto">ONNX protobuf description</a> (or its <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/IR.md">human-readable documentation</a> and the <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md">operator schemas</a> are useful as reference documents. We also provide a Jupyter notebook (<a class="reference external" href="https://github.com/Xilinx/finn/blob/dev/notebooks/1-FINN-HowToWorkWithONNX.ipynb">1-FINN-HowToWorkWithONNX</a>) that can help to get familiar with ONNX by showing how to work with a simple ONNX model in FINN.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>FINN uses ONNX is a specific way that we refer to as FINN-ONNX, and not all ONNX graphs are supported by FINN (and vice versa).</p>
</div>
</div>
<div class="section" id="custom-quantization-annotations">
<h2>Custom Quantization Annotations<a class="headerlink" href="#custom-quantization-annotations" title="Permalink to this headline">¶</a></h2>
<p>ONNX does not support datatypes smaller than 8-bit integers, whereas in FINN we are interested in smaller integers down to ternary and bipolar. To make this work, FINN uses the quantization_annotation field in ONNX to annotate tensors with their FINN DataType (<a class="reference internal" href="source_code/finn.core.html#finn.core.datatype.DataType" title="finn.core.datatype.DataType"><code class="xref py py-mod docutils literal notranslate"><span class="pre">finn.core.datatype.DataType</span></code></a>) information. However, all tensors are expected to use single-precision floating point (float32) storage in FINN. This means we store even a 1-bit value as floating point for the purposes of representation. The FINN compiler flow is responsible for eventually producing a packed representation for the target hardware, where the 1-bit is actually stored as 1-bit.</p>
</div>
<div class="section" id="custom-operations-nodes">
<h2>Custom Operations/Nodes<a class="headerlink" href="#custom-operations-nodes" title="Permalink to this headline">¶</a></h2>
<p>FINN uses many custom operations (op_type in ONNX NodeProto) that are not defined in the ONNX operator schema. These custom nodes are marked with domain=”finn” in the protobuf to identify them as such. These nodes can represent specific operations that we need for low-bit networks, or operations that are specific to a particular hardware backend. To get more familiar with custom operations and how they are created, please take a look in the Jupyter notebook <a class="reference external" href="https://github.com/Xilinx/finn/blob/dev/notebooks/7-FINN-CustomOps.ipynb">7-FINN-CustomOps</a> or directly in the module <a class="reference internal" href="source_code/finn.custom_op.html#module-finn.custom_op" title="finn.custom_op"><code class="xref py py-mod docutils literal notranslate"><span class="pre">finn.custom_op</span></code></a>.</p>
</div>
<div class="section" id="custom-onnx-execution-flow">
<h2>Custom ONNX Execution Flow<a class="headerlink" href="#custom-onnx-execution-flow" title="Permalink to this headline">¶</a></h2>
<p>To verify correct operation of FINN-ONNX graphs, FINN provides its own ONNX execution flow (<a class="reference internal" href="source_code/finn.core.html#module-finn.core.onnx_exec" title="finn.core.onnx_exec"><code class="xref py py-mod docutils literal notranslate"><span class="pre">finn.core.onnx_exec</span></code></a>). This flow supports the standard set of ONNX operations as well as the custom FINN operations.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This execution flow is only meant for checking the correctness of models after applying transformations, and not for high performance inference.</p>
</div>
</div>
<div class="section" id="modelwrapper">
<span id="id1"></span><h2>ModelWrapper<a class="headerlink" href="#modelwrapper" title="Permalink to this headline">¶</a></h2>
<p>FINN provides a ModelWrapper class (<a class="reference internal" href="source_code/finn.core.html#finn.core.modelwrapper.ModelWrapper" title="finn.core.modelwrapper.ModelWrapper"><code class="xref py py-mod docutils literal notranslate"><span class="pre">finn.core.modelwrapper.ModelWrapper</span></code></a>) as a thin wrapper around ONNX to make it easier to analyze and manipulate ONNX graphs. This wrapper provides many helper functions, while still giving full access to the ONNX protobuf representation.</p>
<p>Some of the helper functions are described in more detail below.</p>
<div class="section" id="create-a-modelwrapper-instance">
<h3>Create a ModelWrapper instance<a class="headerlink" href="#create-a-modelwrapper-instance" title="Permalink to this headline">¶</a></h3>
<p>The ModelWrapper instance can be created using a model in .onnx format or by directly passing a ModelProto instance to the wrapper. The code block below gives an example of how to use the wrapper on a model in .onnx format.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">finn.core.modelwrapper</span> <span class="k">import</span> <span class="n">ModelWrapper</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ModelWrapper</span><span class="p">(</span><span class="s2">&quot;model.onnx&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="access-the-onnx-graphproto-through-modelwrapper">
<h3>Access the ONNX GraphProto through ModelWrapper<a class="headerlink" href="#access-the-onnx-graphproto-through-modelwrapper" title="Permalink to this headline">¶</a></h3>
<p>The ONNX ModelProto can be accessed with following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">modelproto</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">model</span>
</pre></div>
</div>
<p>The graph can be accessed using:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">graphproto</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">graph</span>
</pre></div>
</div>
<p>The node list is accessed by:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">nodes</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span>
</pre></div>
</div>
<p>The individual nodes can be selected via their indices.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># first node</span>
<span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p>The number of all nodes can be determined with the len() function in Python.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># number of nodes in the graph</span>
<span class="nb">len</span><span class="p">(</span><span class="n">nodes</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="helper-functions-for-tensors">
<h3>Helper functions for tensors<a class="headerlink" href="#helper-functions-for-tensors" title="Permalink to this headline">¶</a></h3>
<p>A list of all tensors (names) can easily be accessed using:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tensor_list</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_all_tensor_names</span><span class="p">()</span>
</pre></div>
</div>
<p>If we take a single tensor from that list (by index), we can determine their producer or consumer node by using one of the following functions. Note that it may be that a tensor does not have a producer or consumer node, for example if the tensor represents a constant that is already set. In that case <cite>None</cite> will be returned.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># find producer of third tensor in model tensor list</span>
<span class="n">model</span><span class="o">.</span><span class="n">find_producer</span><span class="p">(</span><span class="n">tensor_list</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

<span class="c1"># find consumer of third tensor in model tensor list</span>
<span class="n">model</span><span class="o">.</span><span class="n">find_consumer</span><span class="p">(</span><span class="n">tensor_list</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
<p>Every tensor has a specific shape, to get or to set this shape these functions can be used:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># get tensor shape of third tensor in model tensor list</span>
<span class="n">model</span><span class="o">.</span><span class="n">get_tensor_shape</span><span class="p">(</span><span class="n">tensor_list</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

<span class="c1"># set tensor shape of third tensor in model tensor list</span>
<span class="n">tensor_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]</span>
<span class="n">model</span><span class="o">.</span><span class="n">set_tensor_shape</span><span class="p">(</span><span class="n">tensor_list</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">tensor_shape</span><span class="p">)</span>
</pre></div>
</div>
<p>Optionally, the dtype (container datatype) of the tensor can also be specified as third argument in the set function. By default it is set to TensorProto.FLOAT.</p>
<p>As mentioned above there are FINN DataTypes additional to the container datatype, these can be accessed and set for a tensor with the following functions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># get tensor dataype of third tensor in model tensor list</span>
<span class="n">model</span><span class="o">.</span><span class="n">get_tensor_datatype</span><span class="p">(</span><span class="n">tensor_list</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

<span class="c1"># set tensor datatype of third tensor in model tensor list</span>
<span class="kn">from</span> <span class="nn">finn.core.datatype</span> <span class="k">import</span> <span class="n">DataType</span>

<span class="n">finn_dtype</span> <span class="o">=</span> <span class="n">DataType</span><span class="o">.</span><span class="n">BIPOLAR</span>
<span class="n">model</span><span class="o">.</span><span class="n">set_tensor_datatype</span><span class="p">(</span><span class="n">tensor_list</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">finn_dtype</span><span class="p">)</span>
</pre></div>
</div>
<p>ModelWrapper contains two helper functions for tensor initializers, one to determine the current initializer and one to set the initializer of a tensor. If there is no initializer, None is returned.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># get tensor initializer of third tensor in model tensor list</span>
<span class="n">model</span><span class="o">.</span><span class="n">get_initializer</span><span class="p">(</span><span class="n">tensor_list</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
<p>ModelWrapper contains more useful functions, if you are interested please have a look at the ModelWrapper module (<a class="reference internal" href="source_code/finn.core.html#finn.core.modelwrapper.ModelWrapper" title="finn.core.modelwrapper.ModelWrapper"><code class="xref py py-mod docutils literal notranslate"><span class="pre">finn.core.modelwrapper.ModelWrapper</span></code></a>) directly.</p>
</div>
</div>
<div class="section" id="analysis-pass">
<span id="id2"></span><h2>Analysis Pass<a class="headerlink" href="#analysis-pass" title="Permalink to this headline">¶</a></h2>
<p>An analysis pass traverses the graph structure and produces information about certain properties. It gets the model in the ModelWrapper as input and returns a dictionary of the properties the analysis extracts. If you are interested in how to write an analysis pass for FINN, please take a look at the Jupyter notebook <a class="reference external" href="https://github.com/Xilinx/finn/blob/dev/notebooks/4-FINN-HowToAnalysisPass.ipynb">4-FINN-HowToAnalysisPass</a>. For more details about existing analysis passes in FINN, see module <code class="xref py py-mod docutils literal notranslate"><span class="pre">finn.analysis</span></code>.</p>
</div>
<div class="section" id="transformation-pass">
<span id="id3"></span><h2>Transformation Pass<a class="headerlink" href="#transformation-pass" title="Permalink to this headline">¶</a></h2>
<p>A transformation passes changes (transforms) the given model, it gets the model in the ModelWrapper as input and returns the changed model (ModelWrapper) to the FINN flow. Additional the flag <em>model_was_changed</em> which indicates if a transformation has to be performed more than once, is returned. If you are interested in how to write a transformation pass for FINN, please take a look at the Jupyter notebook <a class="reference external" href="https://github.com/Xilinx/finn/blob/dev/notebooks/5-FINN-HowToTransformationPass.ipynb">5-FINN-HowToTransformationPass</a>. For more details about existing transformation passes in FINN, see module <code class="xref py py-mod docutils literal notranslate"><span class="pre">finn.transformation</span></code>.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="brevitas_export.html" class="btn btn-neutral float-right" title="Brevitas Export" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="end_to_end_flow.html" class="btn btn-neutral float-left" title="End-to-End Flow" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Xilinx

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>