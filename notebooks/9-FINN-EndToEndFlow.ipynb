{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINN - End-to-End Flow\n",
    "-----------------------------------------------------------------\n",
    "This notebook gives an overview about the end to end flow of FINN. From loading an ONNX model from Brevitas, followed by the numerous transformations in FINN and up to the generation of a bitstream that can be used to load an FPGA. \n",
    "\n",
    "We'll use the following showSrc function to print the source code for function calls in the Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "def showSrc(what):\n",
    "    print(\"\".join(inspect.getsourcelines(what)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "-------------\n",
    "1. Preparation of model to pass to FINN\n",
    "2. FINN transformations\n",
    "    * first transformations\n",
    "    * Streamline\n",
    "    * last transformations\n",
    "3. Verification\n",
    "4. Bitstream generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparation of model to pass to FINN\n",
    "FINN expects an ONNX model as input. This can be a model trained with [Brevitas](https://github.com/Xilinx/brevitas). Brevitas is a Pytorch library for quantization-aware training and the FINN Docker image comes with several [example Brevitas networks](https://github.com/maltanar/brevitas_cnv_lfc). To show the FINN end-to-end flow, we'll use the LFC-w1a1 model as example network. The Brevitas export is only briefly described here, for details see Jupyter notebook [3-FINN-Brevitas-network-import](3-FINN-Brevitas-network-import.ipynb).\n",
    "\n",
    "First a few things have to be imported. Then the model can be loaded with the pretrained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/brevitas_cnv_lfc/training_scripts/models/LFC.py:73: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  x = 2.0 * x - torch.tensor([1.0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import brevitas.onnx as bo\n",
    "from models.LFC import LFC\n",
    "\n",
    "lfc = LFC(weight_bit_width=1, act_bit_width=1, in_bit_width=1)\n",
    "trained_lfc_checkpoint = (\"/workspace/brevitas_cnv_lfc/pretrained_models/LFC_1W1A/checkpoints/best.tar\")\n",
    "checkpoint = torch.load(trained_lfc_checkpoint, map_location=\"cpu\")\n",
    "lfc.load_state_dict(checkpoint[\"state_dict\"])\n",
    "bo.export_finn_onnx(lfc, (1, 1, 28, 28), \"lfc_w1_a1.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was now exported, loaded with the pretrained weights and saved under the name \"lfc_w1_a1.onnx\".\n",
    "To visualize the exported model, Netron can be used. Netron is a visualizer for neural networks and allows interactive investigation of network properties. For example, you can click on the individual nodes and view the properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'lfc_w1_a1.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "import netron\n",
    "netron.start(\"lfc_w1_a1.onnx\", port=8081, host=\"0.0.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"http://0.0.0.0:8081/\" style=\"position: relative; width: 100%;\" height=\"400\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"http://0.0.0.0:8081/\" style=\"position: relative; width: 100%;\" height=\"400\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the model in .onnx format, we can work with it using FINN. For that FINN `ModelWrapper` is used. It is a wrapper around the ONNX model which provides several helper functions to make it easier to work with the model. For details see Jupyter notebook [2-FINN-ModelWrapper](2-FINN-ModelWrapper.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.core.modelwrapper import ModelWrapper\n",
    "model = ModelWrapper(\"lfc_w1_a1.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model is prepared and it can be processed in different ways. The principle of FINN are analysis and transformation passes, which can be applied to the model. An analysis pass extracts specific information about the model and returns it to the user in the form of a dictionary. For more details see [4-FINN-HowToAnalysisPass](4-FINN-HowToAnalysisPass.ipynb). A transformation pass changes the model and returns the changed model back to the FINN flow, for more information about transformation passes see notebook [5-FINN-HowToTransformationPass](5-FINN-HowToTransformationPass.ipynb).\n",
    "\n",
    "Since the goal in this notebook is to process the model to such an extent that a bitstream can be generated from it, the focus is on the transformations that are necessary for this. In the next section these are discussed in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. FINN transformations\n",
    "#### First transformations\n",
    "* InferShapes\n",
    "* FoldConstants\n",
    "* GiveUniqueNodeNames\n",
    "* GiveReadableTensorNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first transformations that are taking place are listed above. First, `InferShapes` is applied to the model, in this transformation all tensor shapes are derived and set in ValueInfo of the model. In the next step constants are folded. This means that a node with constant output is replaced by const-only inputs for the next node. Afterwards the nodes and tensors are given unique and readable names. This sequence can be seen below and then the model is saved and visualized with netron. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.infer_shapes import InferShapes\n",
    "from finn.transformation.fold_constants import FoldConstants\n",
    "from finn.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames\n",
    "\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'lfc_w1_a1.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "model.save(\"lfc_w1_a1.onnx\")\n",
    "netron.start(\"lfc_w1_a1.onnx\", port=8081, host=\"0.0.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"http://0.0.0.0:8081/\" style=\"position: relative; width: 100%;\" height=\"400\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"http://0.0.0.0:8081/\" style=\"position: relative; width: 100%;\" height=\"400\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streamline\n",
    "* ConvertSubToAdd\n",
    "* BatchNormToAffine\n",
    "* ConvertSignToThres\n",
    "* MoveScalarAddPastMatMul\n",
    "* MoveScalarMulPastMatMul\n",
    "* MoveAddPastMatMul\n",
    "* CollapseRepeatedAdd\n",
    "* CollapseRepeatedMul\n",
    "* AbsorbAddIntoMultiThreshold\n",
    "* FactorOutMulSignMagnitude\n",
    "* AbsorbMulIntoMultiThreshold\n",
    "* Absorb1BitMulIntoMatMul\n",
    "* RoundAndClipThresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After these transformations, the most complex transformation step occurs. The streamlining transformation is applied to the model. For details see arXiv:1709.04060. The sequence of transformations it contains can be seen above and using the `showSrc()` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Streamline(Transformation):\n",
      "    \"\"\"Apply the streamlining transform, see arXiv:1709.04060.\"\"\"\n",
      "\n",
      "    def apply(self, model):\n",
      "        streamline_transformations = [\n",
      "            ConvertSubToAdd(),\n",
      "            BatchNormToAffine(),\n",
      "            ConvertSignToThres(),\n",
      "            MoveScalarAddPastMatMul(),\n",
      "            MoveScalarMulPastMatMul(),\n",
      "            MoveAddPastMul(),\n",
      "            CollapseRepeatedAdd(),\n",
      "            CollapseRepeatedMul(),\n",
      "            AbsorbAddIntoMultiThreshold(),\n",
      "            FactorOutMulSignMagnitude(),\n",
      "            AbsorbMulIntoMultiThreshold(),\n",
      "            Absorb1BitMulIntoMatMul(),\n",
      "            RoundAndClipThresholds(),\n",
      "        ]\n",
      "        for trn in streamline_transformations:\n",
      "            model = model.transform(trn)\n",
      "            model = model.transform(GiveUniqueNodeNames())\n",
      "            model = model.transform(GiveReadableTensorNames())\n",
      "            model = model.transform(InferDataTypes())\n",
      "        return (model, False)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from finn.transformation.streamline import Streamline\n",
    "showSrc(Streamline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see in the code that different transformations are involved in the streamlining transformation. The individual transformations are described in more detail below. After each transformation step, three further transformations are applied to the model. On the one hand, the node and tensor names are made unique and readable again, on the other hand the transformation `InferDataTypes()` is executed. In this transformation the data types for each tensor are derived and set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last transformations\n",
    "* ConvertBipolarMatMulToXnorPopcount\n",
    "* AbsorbAddIntoMultiThreshold\n",
    "* AbsorbMulIntoMultiThreshold\n",
    "* RoundAndClipThresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Bitstream generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
