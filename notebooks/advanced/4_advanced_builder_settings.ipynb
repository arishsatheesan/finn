{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fcff912",
   "metadata": {},
   "source": [
    "# Advanced Builder settings\n",
    "\n",
    "<font color=\"red\">**Live FINN tutorial:** We recommend clicking **Cell -> Run All** when you start reading this notebook for \"latency hiding\".</font>\n",
    "\n",
    "<img align=\"left\" src=\"../end2end_example/cybersecurity/finn-example.png\" alt=\"drawing\" style=\"margin-right: 20px\" width=\"250\"/>\n",
    "\n",
    "In this notebook, we'll use the FINN compiler to generate an FPGA accelerator with a streaming dataflow architecture from small convolutional network trained on CIFAR-10. The key idea in such architectures is to parallelize across layers as well as within layers by dedicating a proportionate amount of compute resources to each layer, illustrated on the figure to the left. You can read more about the general concept in the [FINN](https://arxiv.org/pdf/1612.07119) and [FINN-R](https://dl.acm.org/doi/pdf/10.1145/3242897) papers. This is done by mapping each layer to a Vitis HLS description, parallelizing each layer's implementation to the appropriate degree and using on-chip FIFOs to link up the layers to create the full accelerator.\n",
    "\n",
    "These implementations offer a good balance of performance and flexibility, but building them by hand is difficult and time-consuming. This is where the FINN compiler comes in: it can build streaming dataflow accelerators from an ONNX description to match the desired throughput."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a830e730",
   "metadata": {},
   "source": [
    "In this tutorial, we will have a more detailed look into the FINN builder tool and explore different options to customize your FINN design. We assume that you have already completed the [Cybersecurity notebooks](../end2end_example/cybersecurity) and that you have a basic understanding of how the FINN compiler works and how to use the FINN builder tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec9a0db",
   "metadata": {},
   "source": [
    "## Outline\n",
    "---------------\n",
    "\n",
    "1. [Introduction to the CNV-w2a2 network](#intro_cnv)\n",
    "2. [Recap default builder flow](#recap_builder)\n",
    "3. [Build steps](#build_step)\n",
    "    1. [How to make a custom build step](#custom_step)\n",
    "4. [Folding configuration json](#folding_config)\n",
    "5. [Additional builder arguments](#builder_arg)\n",
    "    1. [Verification steps](#verify)\n",
    "    2. [Examples for additional builder arguments](#example_args)\n",
    "    3. [Other builder arguments](#other_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbed63f",
   "metadata": {},
   "source": [
    "## Introduction to the CNV-w2a2 network <a id=\"intro_cnv\"></a>\n",
    "\n",
    "The particular quantized neural network (QNN) we will be targeting in this notebook is referred to as CNV-w2a2 and it classifies 32x32 RGB images into one of ten CIFAR-10 classes. All weights and activations in this network are quantized to two bit, with the exception of the input (which is RGB with 8 bits per channel) and the final output (which is 32-bit numbers). It is similar to the convolutional neural network used in the [cnv_end2end_example](../end2end_example/bnn-pynq/cnv_end2end_example.ipynb) Jupyter notebook.\n",
    "\n",
    "\n",
    "You'll have a chance to interactively examine the layers that make up the network in Netron in a moment, so that's enough about the network for now. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce459f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.basic import make_build_dir\n",
    "from finn.util.visualization import showInNetron, showSrc\n",
    "import os\n",
    "    \n",
    "build_dir = os.environ['FINN_ROOT'] + \"/notebooks/advanced\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe262964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from finn.util.test import get_test_model_trained\n",
    "from brevitas.export import export_qonnx\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.core.datatype import DataType\n",
    "\n",
    "cnv = get_test_model_trained(\"CNV\", 2, 2)\n",
    "export_onnx_path = build_dir + \"/end2end_cnv_w2a2_export.onnx\"\n",
    "export_qonnx(cnv, torch.randn(1, 3, 32, 32), export_onnx_path)\n",
    "qonnx_cleanup(export_onnx_path, out_file=export_onnx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f59da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "showInNetron(build_dir+\"/end2end_cnv_w2a2_export.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c764ed76",
   "metadata": {},
   "source": [
    "## Quick recap, how to setup up default builder flow for resource estimations <a id=\"recap_builder\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9007705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "model_dir = os.environ['FINN_ROOT'] + \"/notebooks/advanced\"\n",
    "model_file = model_dir + \"/end2end_cnv_w2a2_export.onnx\"\n",
    "\n",
    "estimates_output_dir = \"output_estimates_only\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(estimates_output_dir):\n",
    "    shutil.rmtree(estimates_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "\n",
    "cfg_estimates = build.DataflowBuildConfig(\n",
    "    output_dir          = estimates_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    target_fps          = 1000000,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    fpga_part           = \"xc7z020clg400-1\",\n",
    "    steps               = build_cfg.estimate_only_dataflow_steps,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e4c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg_estimates);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72de8d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "showInNetron(build_dir+\"/output_estimates_only/intermediate_models/step_convert_to_hls.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e561a91",
   "metadata": {},
   "source": [
    "## Build steps <a id=\"build_step\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fe1186",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join(build_cfg.estimate_only_dataflow_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3ef987",
   "metadata": {},
   "source": [
    "You can have a closer look at each step by either using the `showSrc()` function or by accessing the doc string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313fac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.builder.build_dataflow_steps as build_dataflow_steps\n",
    "print(build_dataflow_steps.step_tidy_up.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029da0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.builder.build_dataflow_steps as build_dataflow_steps\n",
    "showSrc(build_dataflow_steps.step_tidy_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c2c97f",
   "metadata": {},
   "source": [
    "### How to make a custom build step <a id=\"custom_step\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d43cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.pytorch import ToTensor\n",
    "from qonnx.transformation.merge_onnx_models import MergeONNXModels\n",
    "\n",
    "def custom_step_add_pre_proc(model: ModelWrapper, cfg: build.DataflowBuildConfig):\n",
    "    ishape = model.get_tensor_shape(model.graph.input[0].name)\n",
    "    # preprocessing: torchvision's ToTensor divides uint8 inputs by 255\n",
    "    preproc = ToTensor()\n",
    "    export_qonnx(preproc, torch.randn(ishape), \"preproc.onnx\", opset_version=11)\n",
    "    preproc_model = ModelWrapper(\"preproc.onnx\")\n",
    "    # set input finn datatype to UINT8\n",
    "    preproc_model.set_tensor_datatype(preproc_model.graph.input[0].name, DataType[\"UINT8\"])\n",
    "    model = model.transform(MergeONNXModels(preproc_model))\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f00b465",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.environ['FINN_ROOT'] + \"/notebooks/advanced\"\n",
    "model_file = model_dir + \"/end2end_cnv_w2a2_export.onnx\"\n",
    "\n",
    "estimates_output_dir = \"output_pre_proc\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(estimates_output_dir):\n",
    "    shutil.rmtree(estimates_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "build_steps = [\n",
    "    custom_step_add_pre_proc,\n",
    "    \"step_qonnx_to_finn\",\n",
    "    \"step_tidy_up\",\n",
    "    \"step_streamline\",\n",
    "    \"step_convert_to_hls\",\n",
    "    \"step_create_dataflow_partition\",\n",
    "    \"step_target_fps_parallelization\",\n",
    "    \"step_apply_folding_config\",\n",
    "    \"step_minimize_bit_width\",\n",
    "    \"step_generate_estimate_reports\",\n",
    "]\n",
    "\n",
    "cfg_estimates = build.DataflowBuildConfig(\n",
    "    output_dir          = estimates_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    target_fps          = 1000000,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    fpga_part           = \"xc7z020clg400-1\",\n",
    "    steps               = build_steps,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a2bcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg_estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e5651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "showInNetron(build_dir+\"/output_pre_proc/intermediate_models/custom_step_add_pre_proc.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6f1bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.insert_topk import InsertTopK\n",
    "\n",
    "def custom_step_add_post_proc(model: ModelWrapper, cfg: build.DataflowBuildConfig):\n",
    "    model = model.transform(InsertTopK(k=1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57adbb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.environ['FINN_ROOT'] + \"/notebooks/advanced\"\n",
    "model_file = model_dir + \"/end2end_cnv_w2a2_export.onnx\"\n",
    "\n",
    "estimates_output_dir = \"output_pre_and_post_proc\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(estimates_output_dir):\n",
    "    shutil.rmtree(estimates_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "build_steps = [\n",
    "    custom_step_add_pre_proc,\n",
    "    custom_step_add_post_proc,\n",
    "    \"step_qonnx_to_finn\",\n",
    "    \"step_tidy_up\",\n",
    "    \"step_streamline\",\n",
    "    \"step_convert_to_hls\",\n",
    "    \"step_create_dataflow_partition\",\n",
    "    \"step_target_fps_parallelization\",\n",
    "    \"step_apply_folding_config\",\n",
    "    \"step_minimize_bit_width\",\n",
    "    \"step_generate_estimate_reports\",\n",
    "]\n",
    "\n",
    "cfg_estimates = build.DataflowBuildConfig(\n",
    "    output_dir          = estimates_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    target_fps          = 1000000,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    fpga_part           = \"xc7z020clg400-1\",\n",
    "    steps               = build_steps,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0598b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg_estimates);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44127417",
   "metadata": {},
   "outputs": [],
   "source": [
    "showInNetron(build_dir+\"/output_pre_and_post_proc/intermediate_models/step_convert_to_hls.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffbadd1",
   "metadata": {},
   "source": [
    "## Folding configuration json <a id=\"folding_config\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c164040f",
   "metadata": {},
   "source": [
    "To learn about the influence of folding factors/parallelism in FINN, please have a look at this notebook: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75f5634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(build_dir+\"/output_pre_and_post_proc/auto_folding_config.json\", 'r') as json_file:\n",
    "    folding_config = json.load(json_file)\n",
    "\n",
    "print(json.dumps(folding_config, indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba856c28",
   "metadata": {},
   "source": [
    "Hardware configuration for each layer\n",
    "\n",
    "FIFO depths\n",
    "\n",
    "Type of memory/compute resources to be used\n",
    "\n",
    "Parallelism along different dimensions (“PE”, ”SIMD”)\n",
    "\n",
    "Baked-in, decoupled or external parameters\n",
    "\n",
    "Influences almost all flows\n",
    "\n",
    "step_apply_folding_config\n",
    "\n",
    "Values tuned for performance & footprint\n",
    "\n",
    "Many additional constraints not visible from .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f42774",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(build_dir+\"/output_pre_and_post_proc/report/estimate_layer_resources.json\", 'r') as json_file:\n",
    "    json_object = json.load(json_file)\n",
    "\n",
    "print(json.dumps(json_object[\"total\"], indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d177dc",
   "metadata": {},
   "source": [
    "You can manually change, here we generate two new folding configurations with either all lutram or all bram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112af6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all ram_style to LUT RAM\n",
    "for key in folding_config:\n",
    "    if \"ram_style\" in folding_config[key]:\n",
    "        folding_config[key][\"ram_style\"] = \"distributed\" \n",
    "# Save as .json    \n",
    "with open(\"folding_config_all_lutram.json\", \"w\") as jsonFile:\n",
    "    json.dump(folding_config, jsonFile)\n",
    "         \n",
    "# Set all ram_style to BRAM\n",
    "for key in folding_config:\n",
    "    if \"ram_style\" in folding_config[key]:\n",
    "        folding_config[key][\"ram_style\"] = \"block\" \n",
    "# Save as .json    \n",
    "with open(\"folding_config_all_bram.json\", \"w\") as jsonFile:\n",
    "    json.dump(folding_config, jsonFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd9f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.environ['FINN_ROOT'] + \"/notebooks/advanced\"\n",
    "model_file = model_dir + \"/end2end_cnv_w2a2_export.onnx\"\n",
    "\n",
    "estimates_output_dir = \"output_all_lutram\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(estimates_output_dir):\n",
    "    shutil.rmtree(estimates_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "build_steps = [\n",
    "    custom_step_add_pre_proc,\n",
    "    custom_step_add_post_proc,\n",
    "    \"step_qonnx_to_finn\",\n",
    "    \"step_tidy_up\",\n",
    "    \"step_streamline\",\n",
    "    \"step_convert_to_hls\",\n",
    "    \"step_create_dataflow_partition\",\n",
    "    \"step_apply_folding_config\",\n",
    "    \"step_minimize_bit_width\",\n",
    "    \"step_generate_estimate_reports\",\n",
    "]\n",
    "\n",
    "cfg_estimates = build.DataflowBuildConfig(\n",
    "    output_dir          = estimates_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    fpga_part           = \"xc7z020clg400-1\",\n",
    "    steps               = build_steps,\n",
    "    folding_config_file = \"folding_config_all_lutram.json\",\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b647c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg_estimates);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc680178",
   "metadata": {},
   "outputs": [],
   "source": [
    "showInNetron(build_dir+\"/output_all_lutram/intermediate_models/step_generate_estimate_reports.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695ecfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(build_dir+\"/output_all_lutram/report/estimate_layer_resources.json\", 'r') as json_file:\n",
    "    json_object = json.load(json_file)\n",
    "\n",
    "print(json.dumps(json_object[\"total\"], indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e8aaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.environ['FINN_ROOT'] + \"/notebooks/advanced\"\n",
    "model_file = model_dir + \"/end2end_cnv_w2a2_export.onnx\"\n",
    "\n",
    "estimates_output_dir = \"output_all_bram\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(estimates_output_dir):\n",
    "    shutil.rmtree(estimates_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "build_steps = [\n",
    "    custom_step_add_pre_proc,\n",
    "    custom_step_add_post_proc,\n",
    "    \"step_qonnx_to_finn\",\n",
    "    \"step_tidy_up\",\n",
    "    \"step_streamline\",\n",
    "    \"step_convert_to_hls\",\n",
    "    \"step_create_dataflow_partition\",\n",
    "    \"step_apply_folding_config\",\n",
    "    \"step_minimize_bit_width\",\n",
    "    \"step_generate_estimate_reports\",\n",
    "]\n",
    "\n",
    "cfg_estimates = build.DataflowBuildConfig(\n",
    "    output_dir          = estimates_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    fpga_part           = \"xc7z020clg400-1\",\n",
    "    steps               = build_steps,\n",
    "    folding_config_file = \"folding_config_all_bram.json\",\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdc1aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg_estimates);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0388fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "showInNetron(build_dir+\"/output_all_bram/intermediate_models/step_generate_estimate_reports.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60a3efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(build_dir+\"/output_all_bram/report/estimate_layer_resources.json\", 'r') as json_file:\n",
    "    json_object = json.load(json_file)\n",
    "\n",
    "print(json.dumps(json_object[\"total\"], indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a675834",
   "metadata": {},
   "source": [
    "## Additional builder arguments <a id=\"builder_arg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c167f4",
   "metadata": {},
   "source": [
    "### Verification steps <a id=\"verify\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe7318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.builder.build_dataflow_steps as build_dataflow_steps\n",
    "showSrc(build_dataflow_steps.step_tidy_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1aa025",
   "metadata": {},
   "outputs": [],
   "source": [
    "showSrc(build_cfg.VerificationStepType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e157d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get golden io pair from Brevitas and save as .npy files\n",
    "from finn.util.test import get_trained_network_and_ishape, get_example_input, get_topk\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "(brevitas_model, ishape) = get_trained_network_and_ishape(\"cnv\", 2, 2)\n",
    "input_tensor_npy = get_example_input(\"cnv\")\n",
    "input_tensor_torch = torch.from_numpy(input_tensor_npy).float()\n",
    "input_tensor_torch = ToTensor().forward(input_tensor_torch).detach()\n",
    "output_tensor_npy = brevitas_model.forward(input_tensor_torch).detach().numpy()\n",
    "output_tensor_npy = get_topk(output_tensor_npy, k=1)\n",
    "\n",
    "np.save(\"input.npy\", input_tensor_npy)\n",
    "np.save(\"expected_output.npy\", output_tensor_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd3032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.environ['FINN_ROOT'] + \"/notebooks/advanced\"\n",
    "model_file = model_dir + \"/end2end_cnv_w2a2_export.onnx\"\n",
    "\n",
    "estimates_output_dir = \"output_with_verification\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(estimates_output_dir):\n",
    "    shutil.rmtree(estimates_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "build_steps = [\n",
    "    custom_step_add_pre_proc,\n",
    "    custom_step_add_post_proc,\n",
    "    \"step_qonnx_to_finn\",\n",
    "    \"step_tidy_up\",\n",
    "    \"step_streamline\",\n",
    "    \"step_convert_to_hls\",\n",
    "    \"step_create_dataflow_partition\",\n",
    "    \"step_target_fps_parallelization\",\n",
    "    \"step_apply_folding_config\",\n",
    "    \"step_minimize_bit_width\",\n",
    "    \"step_generate_estimate_reports\",\n",
    "]\n",
    "\n",
    "cfg_estimates = build.DataflowBuildConfig(\n",
    "    output_dir          = estimates_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    target_fps          = 1000000,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    fpga_part           = \"xc7z020clg400-1\",\n",
    "    steps               = build_steps,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "    ],\n",
    "    verify_steps=[\n",
    "        build_cfg.VerificationStepType.QONNX_TO_FINN_PYTHON,\n",
    "        build_cfg.VerificationStepType.TIDY_UP_PYTHON,\n",
    "        build_cfg.VerificationStepType.STREAMLINED_PYTHON,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a46e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg_estimates);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b30546",
   "metadata": {},
   "source": [
    "### Examples for additional builder arguments <a id=\"example_args\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfb40e4",
   "metadata": {},
   "source": [
    "#### Standalone Thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddbd686",
   "metadata": {},
   "source": [
    " picture of im2col + matmul + multithreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de55871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.environ['FINN_ROOT'] + \"/notebooks/advanced\"\n",
    "model_file = model_dir + \"/end2end_cnv_w2a2_export.onnx\"\n",
    "\n",
    "estimates_output_dir = \"output_standalone_thresholds\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(estimates_output_dir):\n",
    "    shutil.rmtree(estimates_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "build_steps = [\n",
    "    custom_step_add_pre_proc,\n",
    "    custom_step_add_post_proc,\n",
    "    \"step_qonnx_to_finn\",\n",
    "    \"step_tidy_up\",\n",
    "    \"step_streamline\",\n",
    "    \"step_convert_to_hls\",\n",
    "    \"step_create_dataflow_partition\",\n",
    "    \"step_target_fps_parallelization\",\n",
    "    \"step_apply_folding_config\",\n",
    "    \"step_minimize_bit_width\",\n",
    "    \"step_generate_estimate_reports\",\n",
    "]\n",
    "\n",
    "cfg_estimates = build.DataflowBuildConfig(\n",
    "    output_dir            = estimates_output_dir,\n",
    "    mvau_wwidth_max       = 80,\n",
    "    target_fps            = 1000000,\n",
    "    synth_clk_period_ns   = 10.0,\n",
    "    fpga_part             = \"xc7z020clg400-1\",\n",
    "    standalone_thresholds = True,\n",
    "    steps                 = build_steps,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c143f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg_estimates);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba36f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "showInNetron(build_dir+\"/output_standalone_thresholds/intermediate_models/step_generate_estimate_reports.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b710fd28",
   "metadata": {},
   "source": [
    "#### RTL Convolutional Input Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8249280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.environ['FINN_ROOT'] + \"/notebooks/advanced\"\n",
    "model_file = model_dir + \"/end2end_cnv_w2a2_export.onnx\"\n",
    "\n",
    "estimates_output_dir = \"output_rtl_swg\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(estimates_output_dir):\n",
    "    shutil.rmtree(estimates_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "build_steps = [\n",
    "    custom_step_add_pre_proc,\n",
    "    custom_step_add_post_proc,\n",
    "    \"step_qonnx_to_finn\",\n",
    "    \"step_tidy_up\",\n",
    "    \"step_streamline\",\n",
    "    \"step_convert_to_hls\",\n",
    "    \"step_create_dataflow_partition\",\n",
    "    \"step_target_fps_parallelization\",\n",
    "    \"step_apply_folding_config\",\n",
    "    \"step_minimize_bit_width\",\n",
    "    \"step_generate_estimate_reports\",\n",
    "]\n",
    "\n",
    "cfg_estimates = build.DataflowBuildConfig(\n",
    "    output_dir             = estimates_output_dir,\n",
    "    mvau_wwidth_max        = 80,\n",
    "    target_fps             = 1000000,\n",
    "    synth_clk_period_ns    = 10.0,\n",
    "    fpga_part              = \"xc7z020clg400-1\",\n",
    "    force_rtl_conv_inp_gen = True,\n",
    "    steps                  = build_steps,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e83b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg_estimates);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c45dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "showInNetron(build_dir+\"/output_rtl_swg/intermediate_models/step_generate_estimate_reports.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4609f94d",
   "metadata": {},
   "source": [
    "### Other builder arguments <a id=\"other_args\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b6853d",
   "metadata": {},
   "source": [
    "Let's have a look at the additional builder arguments. We want to only filter out the FINN specific arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f6aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out methods\n",
    "builder_args = [m for m in dir(build_cfg.DataflowBuildConfig) if not m.startswith('_')]\n",
    "print(\"\\n\".join(builder_args))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12ab370",
   "metadata": {},
   "source": [
    "There are attributes that come from the dataclasses-json class: to_dict, to_json, schema, from_json, from_dict. These are not FINN builder specific. Some of the arguments we have seen already in the Cybersecurity notebook and in this notebook, e.g. target_fps, fpga_part, folding_config_file, ...\n",
    "Please have a look here and scroll through the available builder arguments: https://github.com/Xilinx/finn/blob/dev/src/finn/builder/build_dataflow_config.py#L155"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aba0493",
   "metadata": {},
   "source": [
    "So far, in this notebook, we only looked at configurations up to the generation of estimate reports so far, a lot of these builder arguments actually become relevant at a later stage in the FINN flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec39b9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join(build_cfg.default_build_dataflow_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76df000f",
   "metadata": {},
   "source": [
    "You can have a closer look at each step by either using the `showSrc()` function or by accessing the doc string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf49f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.builder.build_dataflow_steps as build_dataflow_steps\n",
    "print(build_dataflow_steps.step_create_dataflow_partition.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec10985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
