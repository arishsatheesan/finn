{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaad116e-9d75-44ff-8b53-d239ab1024b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import onnx\n",
    "import torch\n",
    "\n",
    "model_dir = os.environ['FINN_ROOT'] + \"/notebooks/end2end_example/cybersecurity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e446dedc-cfc1-435d-b6dd-2fe70a6dbd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget -O unsw_nb15_binarized.npz https://zenodo.org/record/4519767/files/unsw_nb15_binarized.npz?download=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf569d65-5e94-4d62-9e7c-113dfcff845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "def get_preqnt_dataset(data_dir: str, train: bool):\n",
    "    unsw_nb15_data = np.load(data_dir + \"/unsw_nb15_binarized.npz\")\n",
    "    if train:\n",
    "        partition = \"train\"\n",
    "    else:\n",
    "        partition = \"test\"\n",
    "    part_data = unsw_nb15_data[partition].astype(np.float32)\n",
    "    part_data = torch.from_numpy(part_data)\n",
    "    part_data_in = part_data[:, :-1]\n",
    "    part_data_out = part_data[:, -1]\n",
    "    return TensorDataset(part_data_in, part_data_out)\n",
    "\n",
    "train_quantized_dataset = get_preqnt_dataset(\".\", True)\n",
    "test_quantized_dataset = get_preqnt_dataset(\".\", False)\n",
    "\n",
    "print(\"Samples in each set: train = %d, test = %s\" % (len(train_quantized_dataset), len(test_quantized_dataset))) \n",
    "print(\"Shape of one input sample: \" +  str(train_quantized_dataset[0][0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7854f17-d7df-44be-9f50-4652b90b37bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "# dataset loaders\n",
    "train_quantized_loader = DataLoader(train_quantized_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_quantized_loader = DataLoader(test_quantized_dataset, batch_size=batch_size, shuffle=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3119f4-ff30-4e29-8cef-fb8b06086679",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for x,y in train_quantized_loader:\n",
    "    print(\"Input shape for 1 batch: \" + str(x.shape))\n",
    "    print(\"Label shape for 1 batch: \" + str(y.shape))\n",
    "    count += 1\n",
    "    if count == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0dd357-7f68-4197-888a-694207e11085",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Target device: \" + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05dba8d-23c0-41e5-bc9c-608bfbc96901",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 593      \n",
    "hidden1 = 64      \n",
    "hidden2 = 64\n",
    "hidden3 = 64\n",
    "weight_bit_width = 2\n",
    "act_bit_width = 2\n",
    "num_classes = 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcce80e-6a82-425d-a8d5-5a8109fb91d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brevitas.nn import QuantLinear, QuantReLU\n",
    "import torch.nn as nn\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "model = nn.Sequential(\n",
    "      QuantLinear(input_size, hidden1, bias=True, weight_bit_width=weight_bit_width),\n",
    "      nn.BatchNorm1d(hidden1),\n",
    "      nn.Dropout(0.5),\n",
    "      QuantReLU(bit_width=act_bit_width),\n",
    "      QuantLinear(hidden1, hidden2, bias=True, weight_bit_width=weight_bit_width),\n",
    "      nn.BatchNorm1d(hidden2),\n",
    "      nn.Dropout(0.5),\n",
    "      QuantReLU(bit_width=act_bit_width),\n",
    "      QuantLinear(hidden2, hidden3, bias=True, weight_bit_width=weight_bit_width),\n",
    "      nn.BatchNorm1d(hidden3),\n",
    "      nn.Dropout(0.5),\n",
    "      QuantReLU(bit_width=act_bit_width),\n",
    "      QuantLinear(hidden3, num_classes, bias=True, weight_bit_width=weight_bit_width)\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccbb834-2d29-4285-9664-9efcba635c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion):\n",
    "    losses = []\n",
    "    # ensure model is in training mode\n",
    "    model.train()    \n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):        \n",
    "        inputs, target = data\n",
    "        inputs, target = inputs.to(device), target.to(device)\n",
    "        optimizer.zero_grad()   \n",
    "                \n",
    "        # forward pass\n",
    "        output = model(inputs.float())\n",
    "        loss = criterion(output, target.unsqueeze(1))\n",
    "        \n",
    "        # backward pass + run optimizer to update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # keep track of loss value\n",
    "        losses.append(loss.data.cpu().numpy()) \n",
    "           \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aad887-4cbd-4630-aad3-b9abd8ad4d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def test(model, test_loader):    \n",
    "    # ensure model is in eval mode\n",
    "    model.eval() \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, target = data\n",
    "            inputs, target = inputs.to(device), target.to(device)\n",
    "            output_orig = model(inputs.float())\n",
    "            # run the output through sigmoid\n",
    "            output = torch.sigmoid(output_orig)  \n",
    "            # compare against a threshold of 0.5 to generate 0/1\n",
    "            pred = (output.detach().cpu().numpy() > 0.5) * 1\n",
    "            target = target.cpu().float()\n",
    "            y_true.extend(target.tolist()) \n",
    "            y_pred.extend(pred.reshape(-1).tolist())\n",
    "        \n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d4a0ed-cf61-4940-8333-0d938a9c0151",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "lr = 0.001 \n",
    "\n",
    "def display_loss_plot(losses, title=\"Training loss\", xlabel=\"Iterations\", ylabel=\"Loss\"):\n",
    "    x_axis = [i for i in range(len(losses))]\n",
    "    plt.plot(x_axis,losses)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940f92b1-c283-4d18-810c-ba03ce9b679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss criterion and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5183fb56-b996-4271-9b81-bbad01c5c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "running_loss = []\n",
    "running_test_acc = []\n",
    "t = trange(num_epochs, desc=\"Training loss\", leave=True)\n",
    "\n",
    "for epoch in t:\n",
    "        loss_epoch = train(model, train_quantized_loader, optimizer,criterion)\n",
    "        test_acc = test(model, test_quantized_loader)\n",
    "        t.set_description(\"Training loss = %f test accuracy = %f\" % (np.mean(loss_epoch), test_acc))\n",
    "        t.refresh() # to show immediately the update           \n",
    "        running_loss.append(loss_epoch)\n",
    "        running_test_acc.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178c896c-d252-4c29-bf76-62a82703c658",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss_per_epoch = [np.mean(loss_per_epoch) for loss_per_epoch in running_loss]\n",
    "display_loss_plot(loss_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4a8df9-04c6-42c8-be86-36dd4ca6a645",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_per_epoch = [np.mean(acc_per_epoch) for acc_per_epoch in running_test_acc]\n",
    "display_loss_plot(acc_per_epoch, title=\"Test accuracy\", ylabel=\"Accuracy [%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e3e0c-30f9-495a-bb89-c10bde747950",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, test_quantized_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d8a08d-0544-4b37-8a0f-693c049f624e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Brevitas model to disk\n",
    "torch.save(model.state_dict(), \"state_dict_self-trained.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7071f09-b96b-4e23-aeed-34577c1e7388",
   "metadata": {},
   "source": [
    "# Network Surgery Before Export <a id=\"network_surgery\"></a>\n",
    "\n",
    "Sometimes, it's desirable to make some changes to our trained network prior to export (this is known in general as \"network surgery\"). This depends on the model and is not generally necessary, but in this case we want to make a couple of changes to get better results with FINN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980256f9-e907-4c58-86b6-17583dc6e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model to CPU before surgery\n",
    "model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ce9900-069a-49e5-8275-112ec1fca5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "modified_model = deepcopy(model)\n",
    "\n",
    "W_orig = modified_model[0].weight.data.detach().numpy()\n",
    "W_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3282a17b-f47a-4adb-9cb3-f7f2ae4c682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# pad the second (593-sized) dimensions with 7 zeroes at the end\n",
    "W_new = np.pad(W_orig, [(0,0), (0,7)])\n",
    "W_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0124457-7dd0-47e9-aaa1-b6e3ab0e73dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_model[0].weight.data = torch.from_numpy(W_new)\n",
    "modified_model[0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a56df1e-fc95-4cbb-a8ac-fd0d104a1eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brevitas.nn import QuantIdentity\n",
    "\n",
    "\n",
    "class CybSecMLPForExport(nn.Module):\n",
    "    def __init__(self, my_pretrained_model):\n",
    "        super(CybSecMLPForExport, self).__init__()\n",
    "        self.pretrained = my_pretrained_model\n",
    "        self.qnt_output = QuantIdentity(\n",
    "            quant_type='binary', \n",
    "            scaling_impl_type='const',\n",
    "            bit_width=1, min_val=-1.0, max_val=1.0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # assume x contains bipolar {-1,1} elems\n",
    "        # shift from {-1,1} -> {0,1} since that is the\n",
    "        # input range for the trained network\n",
    "        x = (x + torch.tensor([1.0]).to(x.device)) / 2.0  \n",
    "        out_original = self.pretrained(x)\n",
    "        out_final = self.qnt_output(out_original)   # output as {-1,1}     \n",
    "        return out_final\n",
    "\n",
    "model_for_export = CybSecMLPForExport(modified_model)\n",
    "model_for_export.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff4b9fc-ae7c-467b-90a8-4f5a9bf029fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_padded_bipolar(model, test_loader):    \n",
    "    # ensure model is in eval mode\n",
    "    model.eval() \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, target = data\n",
    "            inputs, target = inputs.to(device), target.to(device)\n",
    "            # pad inputs to 600 elements\n",
    "            input_padded = torch.nn.functional.pad(inputs, (0,7,0,0))\n",
    "            # convert inputs to {-1,+1}\n",
    "            input_scaled = 2 * input_padded - 1\n",
    "            # run the model\n",
    "            output = model(input_scaled.float())\n",
    "            y_pred.extend(list(output.flatten().cpu().numpy()))\n",
    "            # make targets bipolar {-1,+1}\n",
    "            expected = 2 * target.float() - 1\n",
    "            expected = expected.cpu().numpy()\n",
    "            y_true.extend(list(expected.flatten()))\n",
    "        \n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107e9d99-2009-446a-9bf6-9185a55e369b",
   "metadata": {},
   "source": [
    "# Export to QONNX and Conversion to FINN-ONNX <a id=\"export_qonnx\" ></a>\n",
    "\n",
    "\n",
    "[ONNX](https://onnx.ai/) is an open format built to represent machine learning models, and the FINN compiler expects an ONNX model as input. We'll now export our network into ONNX to be imported and used in FINN for the next notebooks. Note that the particular ONNX representation used for FINN differs from standard ONNX, you can read more about this [here](https://finn.readthedocs.io/en/latest/internals.html#intermediate-representation-finn-onnx).\n",
    "\n",
    "You can see below how we export a trained network in Brevitas into a FINN-compatible ONNX representation (QONNX). QONNX is the format we can export from Brevitas, to feed it into the FINN compiler, we will need to make a conversion to the FINN-ONNX format which is the intermediate representation the compiler works on. The conversion of the FINN-ONNX format is a FINN compiler transformation and to be able to apply it to our model, we will need to wrap it into [ModelWrapper](https://finn.readthedocs.io/en/latest/internals.html#modelwrapper). This is a wrapper around the ONNX model which provides several helper functions to make it easier to work with the model. Then we can call the conversion function to obtain the model in FINN-ONNX format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca04d952-ebbe-4ef7-a963-d5876af0c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brevitas.export import export_qonnx\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.core.datatype import DataType\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "\n",
    "ready_model_filename = model_dir + \"/cybsec-mlp-ready.onnx\"\n",
    "input_shape = (1, 600)\n",
    "\n",
    "# create a QuantTensor instance to mark input as bipolar during export\n",
    "input_a = np.random.randint(0, 1, size=input_shape).astype(np.float32)\n",
    "input_a = 2 * input_a - 1\n",
    "scale = 1.0\n",
    "input_t = torch.from_numpy(input_a * scale)\n",
    "\n",
    "#Move to CPU before export\n",
    "model_for_export.cpu()\n",
    "\n",
    "# Export to ONNX\n",
    "export_qonnx(\n",
    "    model_for_export, export_path=ready_model_filename, input_t=input_t\n",
    ")\n",
    "\n",
    "# clean-up\n",
    "qonnx_cleanup(ready_model_filename, out_file=ready_model_filename)\n",
    "\n",
    "# ModelWrapper\n",
    "model = ModelWrapper(ready_model_filename)\n",
    "# Setting the input datatype explicitly because it doesn't get derived from the export function\n",
    "model.set_tensor_datatype(model.graph.input[0].name, DataType[\"BIPOLAR\"])\n",
    "model = model.transform(ConvertQONNXtoFINN())\n",
    "model.save(ready_model_filename)\n",
    "\n",
    "print(\"Model saved to %s\" % ready_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4866b6d4-6efe-4cf9-9168-54cb9d9ad5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "showInNetron(ready_model_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
